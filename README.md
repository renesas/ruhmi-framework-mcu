

# RUHMI, Robust Unified Heterogeneous Model Integration, Framework supports AI model optimization and deployment with powered by EdgeCortix© MERA™.

## License
(C) Copyright EdgeCortix, Inc. 2025 (C) Copyright Renesas Electronics Corporation 2025 Contributors Licensed under an Apache-2.0 license.  

## Introduction
RUHMI Framework povides a compiler and the necessary tools to convert machine learning models into C source code compatible with range of Renesas MCUs powered by Arm Ethos-U NPUs.
The software stack generates C source code while ensuring compatibility and tight integration the with Renesas e2 studio.
It also ships with Quantizer, a post-training static INT8 quantizer, allowing more demanding models to meet the memory and latency constraints typical of microcontrollers and Ethos-U accelerators.

## Overall workflow
  • **Import:** RUHMI Framework accept models from the most used ML frameworks as PyTorch, TensorFlow Lite and ONNX.  
  • **Compile:** the compiler lowers the graph, applies operator fusion, inserts fast math libraries, and emits plain C99 source code that calls either CMSIS-NN (for Cortex-M CPUs) or the Ethos-U driver depending on the platform. This C code builds inside Renesas e2studio providing support for HAL, Ethos-U drivers, OSPI Flash drivers, CMSIS-NN/CMSIS DSP libraries and other stacks necessary to run machine learning models on the different supported platform.  
  • **Quantize:** when targeting more resource limited devices, MERA Quantizer helps to convert weights and activations to INT8 precision. This tool performs layer-wise calibration on representative data, calculates quantization parameters and emits a quantized model that can be further compiled by the MERA compiler.  
  • **Build & deploy:** Renesas e2studio is compatible with the code generated by the software stack. The same flow works for pure MCU platforms or for MCU + NPU combinations

## Supported embedded platforms  
  • EK-RA8P1 board (device R7KA8P1KFLCAC)  

## Installation - Ubuntu Linux
In order to install RUHMI Framework on supported environment you will need:  
  • A machine with Ubuntu 22.04 installation is recommended as this was the version used for testing  
  • A working installation of PyEnv or other Python virtual environment management system that provides Python version 3.10.x.  

[Installation Guide](/install/README.md)

## Installation - Windows
The software stack is also provided as PIP package compatible with Windows 11.
In order to install RUHMI Framework on supported environment you will need:  
• A machine with Windows 10 or 11. Windows 11 is recommended as this was the version used for testing   
• A working installation of PyEnv or other Python virtual environment management system that provides Python version 3.10.x.  
• Microsoft C++ runtime libraries   

  [Installation Guide](/install/README.md)

## How to deploy models  
The sample script shows how to use the deployment API to compile an already quantized TFLite model on a board with Ethos-U55 support.  

### Deploy to CPU only   
By running the provided script scripts/mcu_deploy.py we can compile the model for MCU only:  
  ``
  cd scripts/  
  python mcu_deploy.py --ref_data ../models_int8 deploy_qtzed  
  ``

This release provides some tested models, if the models provided are for example:  
```
  models_int8/  
  ├── ad_medium_int8.tflite
  ├── kws_micronet_m.tflite
  ├── mobilenet_v2_1.0_224_INT8.tflite
  ├── person-det.tflite
  ├── rnnoise_INT8.tflite
  ├── vww4_128_128_INT8.tflite
  ├── wav2letter_int8.tflite
  ├── yolo-fastest_192_face_v4.tflite
```

### deploy to CPU with Ethos U55 supported:    
When enabling Ethos-U support:  
```
cd scripts/  
python mcu_deploy.py --ethos --ref_data ../models_int8 deploy_qtzed_ethos  
 ```

you will get the following results:
```
    deploy_qtzed
    ├── ad_medium_int8_no_ospi
    ├── kws_micronet_m_no_ospi
    ├── mobilenet_v2_1.0_224_INT8_ospi
    ├── person-det_no_ospi
    ├── rnnoise_INT8_no_ospi
    ├── vww4_128_128_INT8_no_ospi
    ├── wav2letter_int8_ospi
    ├── yolo-fastest_192_face_v4_no_ospi
```

When Ethos-U support is enabled, each of the directories contain a deployment of the corresponding model for MCU + Ethos-U55 platform:  
```
└── [ad_medium_int8_no_ospi]  # an example for "ad_medium_int8_no_ospi"  
    ├── build  
        ├── MCU  
            ├── compilation  
                ├── mera.plan  
                ├── src     # compilation results: C source code and C++ testing support code # HAL entry example  
                    ├── CMakeLists.txt  
                    ├── compare.cpp  
                    ├── compute_sub_0000.c # CPU subgraph generated C source code  
                    ├── compute_sub_0000.h  
                    ├── ...  
                    ├── ethosu_common.h  
                    ├── hal_entry.c  
                    ├── kernel_library_int.c # kernel library if CPU subgraphs are present  
                    ├──  ...  
                    ├── model.c  
                    ├── model.h  
                    ├── model_io_data.c  
                    ├── model_io_data.h  
                    ├── python_bindings.cpp  
                    ├── sub_0001_command_stream.c # Ethos-U55 subgraph generated C source code  
                    ├── sub_0001_command_stream.h  
                    ├── sub_0001_invoke.c  
                    ├── sub_0001_invoke.h  
                    ├──  ...  
                ├──  ...  
            ├── deploy_cfg.json  
            ├── ir_dumps  
                ├── person-det_can.dot  
                ├── ...  
            ├── person-det_after_canonicalization.dot  
            ├── person-det_subgraphs.dot  
    ├── logs  
    ├──　model  
        ├── input_desc.json  
    ├── project.mdp  
```
  
The generated C code under **build/MCU/compilation/src** can be incorporated into a e2studio project.
  [The detailed description of deploy API](scripts/README.md)

## Quantize and deploy models 
If the starting point it is a Float32 precision model, it is possible to use the Quantizer to first quantize the model and finally deploy with MCU/Ethos-U55 support.
The sample script with using the Quantizer can be refred.

To run the script:
  ``
  cd scripts/
  # deploy for MCU only
  python mcu_quantize.py ../models_fp32 deploy_mcu

  # deploy for MCU+Ethos-U55
  python mcu_quantize.py -e ../models_fp32_ethos deploy_ethos
  ``

   [The detailed description of deploy API](scripts/README.md)



# このセクションの内容は要相談

## Guide to the generated C source code
After processing a model, you will find several files on your deployment directory. This include some deploying artifacts generated during compilation that are worth to be kept around for debugging purposes.
The most important output is found under the directory **<deployment_directory>build/MCU/compilation/src**. 
This directory contains the model converted into a set of C99 source code files.


### Runtime API - MPU only deployment
When a model is converted into source code with RUHMI compiler without Ethos-U support, all the operators in the model being deployed will be prepared to be run on CPU/MCU only. 
In this case, the generated code will refer to a single subgraph compute_sub_0000<suffix>, by default, when no suffix is provided, the name of the header that need to included on your application entry point is compute_sub_0000.h.
This header provides the declaration of a C function that if called it will run the model with the provided inputs and write the results on the provided output buffers:

It provides to the user the possibility of providing a buffer to hold intermediate outputs of the model. And this size if provided in compilation time as the value <u>kBufferSize_sub_0000</u> so the user can use this size to allocate the buffer on the stack, the heap or a custom data section.

### Runtime API - MPU + Ethos-U deployment

If Ethos-U support is enabled during conversion into source code with MERA compiler then an arbitrary amount of subgraphs for either CPU or Ethos-U will be generated. Each of these subgraphs will correspond to generated C functions to run the corresponding section of the model on CPU or Ethos. Each function call will get its inputs from previous outputs of other subgraphs and write its outputs on buffers that are designated to became again inputs to other
functions and so on. To make easier for the user to invoke these models where CPU and NPU are involved, the generated code will automate this process and provide a single function that will orchestrate the calls to the different computation
units named void RunModel(bool clean_outputs) and helpers to access to each of the input and output areas at model level not per subgraph level. The runtime API header when Ethos-U is enabled can be found on a file named model.h
under the same directory <deployment_directory>/build/MCU/compilation/src.
For example, after enabling Ethos-U support for a model with two inputs and three outputs MERA provides the next runtime API:

# ここまで

## ERROR list  
  [The ERROR list](doc/error.md)

## AI model compile API Specification  
  [The AI model compile API](doc/compile_api.md)






